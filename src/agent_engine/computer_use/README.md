# Agent Computer Use - Refactored Architecture

## ğŸ¯ Overview

This is a completely refactored computer automation system that transforms a monolithic 1700+ line file into a clean, maintainable architecture with clear separation of concerns.

## ğŸ“ Architecture

```
computer_use/
â”œâ”€â”€ _agent_orchestrator.py      # MAIN FILE - Pure pseudocode orchestration
â”œâ”€â”€ adapters/                   # LLM providers (OpenAI, Ollama, etc.)
â”œâ”€â”€ actions/                    # Action execution (click, type, etc.)
â”œâ”€â”€ session/                    # Logging, performance, conversation
â”œâ”€â”€ ui/                         # UI formatting and state management
â”œâ”€â”€ workflow/                   # Task execution, completion detection
â”œâ”€â”€ prompts/                    # File-based prompt system
â””â”€â”€ utils/                      # Helper functions (extracted from main)
```

## ğŸµ The Orchestrator Pattern

The `_agent_orchestrator.py` file is designed to read like **pure pseudocode**:

### Key Principles:
- **NO helper functions** - only delegation to specialized modules
- **NO business logic** - pure coordination
- **Reads like a conductor's score** - tells each musician (module) when to play
- **Perfect for junior developers** - easy to understand workflow

### Main Workflow:
```python
async def execute_task(task):
    # 1. Setup task tracking
    setup_logging_and_tracking()
    
    # 2. Execute each iteration  
    for iteration in range(max_iterations):
        llm_response = get_llm_decision()      # Delegate to LLM adapter
        result = execute_action(llm_response)   # Delegate to action executors
        check_completion(result)                # Delegate to completion detector
        update_tracking(result)                 # Delegate to session manager
    
    # 3. Provide summary
    generate_summary()                          # Delegate to logger
```

## ğŸ—ï¸ Module Responsibilities

Each module has **one clear responsibility**:

- **Adapters**: Talk to different AI models (OpenAI, Ollama, OpenRouter)
- **Actions**: Perform UI/system actions (click, type, bash, etc.)
- **Session**: Log everything and track performance
- **UI**: Understand and format screen state for LLMs
- **Workflow**: Detect task completion and manage app context
- **Prompts**: Load and format all prompt templates from files
- **Utils**: Helper functions extracted from main orchestrator

## ğŸ¯ Benefits Achieved

1. **Readability**: Main file reads like pseudocode
2. **Maintainability**: ~100-200 lines per file vs 1700 lines
3. **Testability**: Each module can be tested independently
4. **Extensibility**: Easy to add new providers/actions/workflows
5. **Separation of Concerns**: Each module has one responsibility
6. **Prompt Management**: Non-developers can edit prompts without code
7. **LLM Agnostic**: Works with any LLM provider

## ğŸš€ Usage

```python
# New way (recommended)
from src.agent_engine.computer_use import AgentOrchestrator
agent = AgentOrchestrator()
await agent.execute_task("Open Safari and go to apple.com")

# Simple and direct usage
from src.agent_engine.computer_use import AgentOrchestrator
agent = AgentOrchestrator()
```

## ğŸ“ File-Based Prompts

All prompts are now in separate files:

```
prompts/
â”œâ”€â”€ system.txt              # Main system prompt
â”œâ”€â”€ action_guide.txt        # Available actions
â”œâ”€â”€ coordinate_guide.txt    # Coordinate system
â””â”€â”€ dynamic/               # Dynamic prompt templates
    â”œâ”€â”€ messages.txt       # Messages app guidance
    â”œâ”€â”€ completion.txt     # Task completion
    â””â”€â”€ efficiency.txt     # Performance tips
```

This allows non-developers to edit prompts without touching code!

## ğŸ­ The Orchestrator Philosophy

The orchestrator follows the **"conductor pattern"**:
- It knows WHAT needs to happen (the score)
- It delegates HOW to specialized modules (the musicians)
- It coordinates WHEN things happen (the timing)
- It never performs the actual work itself

This creates code that is:
- **Predictable**: Always follows the same pattern
- **Debuggable**: Easy to trace what's happening
- **Maintainable**: Changes are isolated to specific modules
- **Readable**: Flows like natural language